{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44282607",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#000;\"><img src=\"pqn.png\"></img></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca26c13",
   "metadata": {},
   "source": [
    "## Library installation\n",
    "Install the libraries we use so the notebook runs anywhere without manual setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909a1c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install yfinance pandas numpy matplotlib seaborn statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88e4eb9",
   "metadata": {},
   "source": [
    "These are standard pip packages that cover data access (yfinance), manipulation (pandas, numpy), testing (statsmodels), and plotting (matplotlib, seaborn). If you use conda, you can install the same names via conda-forge to avoid binary build issues on some systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5128b83a",
   "metadata": {},
   "source": [
    "## Imports and setup\n",
    "We use matplotlib and seaborn for plotting, numpy and pandas for array/DataFrame work, yfinance to fetch historical prices, and statsmodels’ coint for the Engle–Granger cointegration test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530046a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "from statsmodels.tsa.stattools import coint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2af95ae",
   "metadata": {},
   "source": [
    "These imports set up a minimal stack that mirrors how professionals prototype stat-arb: get data, test the relationship, and visualize the spread. Keeping the toolset small helps us focus on the mechanics (stationarity and residuals) rather than juggling libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af07d50c",
   "metadata": {},
   "source": [
    "## Define universe and download data\n",
    "Define a related renewable-energy universe and pull daily closes, then align the panel by dropping dates with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1687414",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = [\n",
    "    \"NEE\",\n",
    "    \"FSLR\",\n",
    "    \"ENPH\",\n",
    "    \"PLUG\",\n",
    "    \"BEP\",\n",
    "    \"AQN\",\n",
    "    \"PBW\",\n",
    "    \"FAN\",\n",
    "    \"ICLN\",\n",
    "]\n",
    "start_date = \"2014-01-01\"\n",
    "end_date = \"2015-01-01\"\n",
    "df = yf.download(\n",
    "    tickers,\n",
    "    start=start_date,\n",
    "    end=end_date,\n",
    "    auto_adjust=False,\n",
    ").Close\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68406a2",
   "metadata": {},
   "source": [
    "Starting with related names increases our odds of finding economic links that support a stable residual, rather than spurious correlation. Dropping missing dates ensures the Engle–Granger test compares like-for-like observations, which protects your inference. The short window is for illustration; in practice, use longer histories and time splits to reduce sampling noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad45526",
   "metadata": {},
   "source": [
    "## Test cointegration and select pairs\n",
    "Run Engle–Granger tests across all pairs to score stability (p-values) and keep candidates below a permissive threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7d2f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(tickers)\n",
    "score_matrix = np.zeros((n, n))\n",
    "pvalue_matrix = np.ones((n, n))\n",
    "pairs = []\n",
    "for i in range(n):\n",
    "    for j in range(i + 1, n):\n",
    "        score, pval, _ = coint(df.iloc[:, i], df.iloc[:, j])\n",
    "        score_matrix[i, j] = score\n",
    "        pvalue_matrix[i, j] = pval\n",
    "        if pval < 0.10:\n",
    "            pairs.append((tickers[i], tickers[j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9e1748",
   "metadata": {},
   "source": [
    "Cointegration targets a stationary linear combination, which is what makes residual trading coherent when volatility shifts. A 10% screen is deliberately loose so we don’t overfit at this stage; we’ll rely on later standardization and validation to refine signals. In production research, account for multiple testing and re-estimate over rolling windows to keep parameters current."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dfe0d3",
   "metadata": {},
   "source": [
    "Identify the strongest candidate (lowest p-value) and extract its two aligned price series for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b1274a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.triu(np.ones_like(pvalue_matrix, dtype=bool), k=1)\n",
    "upper_vals = pvalue_matrix[mask]\n",
    "min_idx_flat = np.argmin(upper_vals)\n",
    "min_p = upper_vals[min_idx_flat]\n",
    "idx_pairs = np.column_stack(np.where(mask))\n",
    "i, j = idx_pairs[min_idx_flat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8518ba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "S1, S2 = df.iloc[:, i], df.iloc[:, j]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3555e3",
   "metadata": {},
   "source": [
    "Picking the best-ranked pair gives us a concrete example to carry through the workflow. Remember that the test is symmetric, but the tradable spread is not—next we should estimate a hedge ratio so the residual reflects the true linear relation rather than raw price levels. Treat this selection as a starting point to be confirmed out-of-sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e585a9",
   "metadata": {},
   "source": [
    "## Standardize residuals and visualize signals\n",
    "Reconfirm the cointegration result on the chosen pair, then build a spread and a rolling z-score to make signals comparable over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d303266",
   "metadata": {},
   "outputs": [],
   "source": [
    "score, pvalue, _ = coint(S1, S2)\n",
    "print(\n",
    "    f\"tickers with lowest p-value: {tickers[i]} x {tickers[j]}, p={pvalue}\"\n",
    ")\n",
    "spread = S1 - S2\n",
    "zscore = (\n",
    "    spread - spread.rolling(21, min_periods=21).mean()\n",
    ") / spread.rolling(21, min_periods=21).std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcba250b",
   "metadata": {},
   "source": [
    "Standardizing with a 21-day rolling window avoids lookahead and puts the residual in “number of sigmas,” which makes entry and exit rules clean. The spread here is a simple difference; in practice, regress S1 on S2 and use residual = S1 − beta*S2 to respect scaling. Z-scores are portable across pairs and regimes, which helps when you later compare signals or batch-trade a basket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c5308e",
   "metadata": {},
   "source": [
    "Visualize the cointegration p-values, masking non-candidates and the redundant lower triangle to see which names truly co-move in a stable way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e23505",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (\n",
    "    np.tril(np.ones_like(pvalue_matrix, dtype=bool))\n",
    "    | (pvalue_matrix >= 0.10)\n",
    ")\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    pvalue_matrix,\n",
    "    mask=mask,\n",
    "    xticklabels=tickers,\n",
    "    yticklabels=tickers,\n",
    "    cmap=\"RdYlGn_r\",\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cbar=True,\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    ")\n",
    "plt.title(\"Cointegration Test p-value Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00284a2",
   "metadata": {},
   "source": [
    "A heatmap helps us spot clusters of stable relationships within the renewable theme, which is more actionable than eyeballing charts. This is how we define a tradable subset before doing any signal tuning. Keep in mind that what looks good in one year may drift, so periodic re-tests are part of a robust workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4970e1",
   "metadata": {},
   "source": [
    "Plot the raw spread with simple bands and the standardized z-score so we can sketch an entry/exit plan around mean reversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a5dbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8), sharex=True)\n",
    "axes[0].plot(spread.index, spread, label=\"Spread\")\n",
    "axes[0].axhline(spread.mean(), color=\"black\", linestyle=\"--\", lw=1)\n",
    "axes[0].axhline(\n",
    "    spread.mean() + spread.std(),\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    lw=1,\n",
    ")\n",
    "axes[0].axhline(\n",
    "    spread.mean() - spread.std(),\n",
    "    color=\"green\",\n",
    "    linestyle=\"--\",\n",
    "    lw=1,\n",
    ")\n",
    "axes[0].set_ylabel(\"Spread\")\n",
    "axes[0].legend()\n",
    "axes[1].plot(zscore.index, zscore, label=\"Z-score\")\n",
    "axes[1].axhline(0, color=\"black\", linestyle=\"--\", lw=1)\n",
    "axes[1].axhline(1, color=\"red\", linestyle=\"--\", lw=1)\n",
    "axes[1].axhline(-1, color=\"green\", linestyle=\"--\", lw=1)\n",
    "axes[1].set_ylabel(\"Z-score\")\n",
    "axes[1].legend()\n",
    "plt.xlabel(\"Date\")\n",
    "plt.suptitle(\"Spread and Rolling Z-score between ABGB and FSLR\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f264a9",
   "metadata": {},
   "source": [
    "Z-score bands make the rules explicit: for example, consider entries beyond ±1 and exits near 0, then evaluate with costs and borrow constraints. Treat these pictures as diagnostics; the next step is to backtest with rolling hedge-ratio estimation so bands reflect the true residual. Static thresholds are a useful baseline, but the edge lives in disciplined estimation and risk controls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48eb190",
   "metadata": {},
   "source": [
    "<a href=\"https://pyquantnews.com/\">PyQuant News</a> is where finance practitioners level up with Python for quant finance, algorithmic trading, and market data analysis. Looking to get started? Check out the fastest growing, top-selling course to <a href=\"https://gettingstartedwithpythonforquantfinance.com/\">get started with Python for quant finance</a>. For educational purposes. Not investment advice. Use at your own risk."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
