{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e13693f",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#000;\"><img src=\"pqn.png\"></img></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a83b5ca",
   "metadata": {},
   "source": [
    "## Library installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76831c7",
   "metadata": {},
   "source": [
    "Install the runtime dependencies so this notebook runs anywhere without manual setup. We include yfinance, pandas, numpy, and matplotlib for data, arrays, and plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c60b3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install yfinance pandas numpy matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713da31a",
   "metadata": {},
   "source": [
    "We install pandas even if we do not import it directly because yfinance returns pandas DataFrames and Series. A single cell like this removes environment friction and makes the notebook portable. No special system packages are typically required for these libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3218b8",
   "metadata": {},
   "source": [
    "## Imports and setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3c51b1",
   "metadata": {},
   "source": [
    "We import math for constants and square roots, numpy for fast elementwise log operations, yfinance to fetch OHLCV bars, and matplotlib.pyplot to plot the close and our volatility estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54637b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8369240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129d715f",
   "metadata": {},
   "source": [
    "Keeping imports minimal helps focus on measurement rather than tooling. yfinance returns pandas objects, so we can use rolling windows without importing pandas explicitly. These are the only modules we need to build, compare, and visualize the estimators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a2b7ad",
   "metadata": {},
   "source": [
    "## Download OHLCV data for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931aff52",
   "metadata": {},
   "source": [
    "Download daily OHLCV for AAPL over a multi-year span to feed each estimator with realistic bar information. This includes Open, High, Low, Close that capture intraday ranges and overnight gaps we care about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3198e4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "data = yf.download(\"AAPL\", start=\"2017-01-01\", end=\"2022-06-30\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8e82ab",
   "metadata": {},
   "source": [
    "Bar data avoids the close-only trap by retaining the range inside each session and the discontinuity between sessions. A longer sample improves stability of rolling statistics, but we will still see small-sample effects in short windows. You can swap the ticker or dates later to pressure-test how robust your sizing metric is across regimes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbcb5bc",
   "metadata": {},
   "source": [
    "## Define realized volatility estimators clearly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2b85af",
   "metadata": {},
   "source": [
    "Implement six realized volatility estimators on OHLC bars, all annualized to trading_periods and computed with rolling windows that avoid lookahead by using only past data. Each function returns a Series aligned with the input index and can drop warm-up NaNs via clean=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69aa31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_deviation(price_data, window=30, trading_periods=252, clean=True):\n",
    "    log_return = (price_data[\"Close\"] / price_data[\"Close\"].shift(1)).apply(np.log)\n",
    "\n",
    "    result = (\n",
    "        log_return.rolling(window=window, center=False).std()\n",
    "        * math.sqrt(trading_periods)\n",
    "    )\n",
    "\n",
    "    if clean:\n",
    "        return result.dropna()\n",
    "    else:\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da8695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parkinson(price_data, window=30, trading_periods=252, clean=True):\n",
    "    rs = (1.0 / (4.0 * math.log(2.0))) * (\n",
    "        (price_data[\"High\"] / price_data[\"Low\"]).apply(np.log)\n",
    "    ) ** 2.0\n",
    "\n",
    "    def f(v):\n",
    "        return (trading_periods * v.mean()) ** 0.5\n",
    "\n",
    "    result = rs.rolling(window=window, center=False).apply(func=f)\n",
    "\n",
    "    if clean:\n",
    "        return result.dropna()\n",
    "    else:\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ba5f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def garman_klass(price_data, window=30, trading_periods=252, clean=True):\n",
    "    log_hl = (price_data[\"High\"] / price_data[\"Low\"]).apply(np.log)\n",
    "    log_co = (price_data[\"Close\"] / price_data[\"Open\"]).apply(np.log)\n",
    "\n",
    "    rs = 0.5 * log_hl ** 2 - (2 * math.log(2) - 1) * log_co ** 2\n",
    "\n",
    "    def f(v):\n",
    "        return (trading_periods * v.mean()) ** 0.5\n",
    "\n",
    "    result = rs.rolling(window=window, center=False).apply(func=f)\n",
    "\n",
    "    if clean:\n",
    "        return result.dropna()\n",
    "    else:\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad975476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hodges_tompkins(price_data, window=30, trading_periods=252, clean=True):\n",
    "    log_return = (price_data[\"Close\"] / price_data[\"Close\"].shift(1)).apply(np.log)\n",
    "\n",
    "    vol = (\n",
    "        log_return.rolling(window=window, center=False).std()\n",
    "        * math.sqrt(trading_periods)\n",
    "    )\n",
    "\n",
    "    h = window\n",
    "    n = (log_return.count() - h) + 1\n",
    "\n",
    "    adj_factor = 1.0 / (\n",
    "        1.0 - (h / n) + ((h ** 2 - 1) / (3 * (n ** 2)))\n",
    "    )\n",
    "\n",
    "    result = vol * adj_factor\n",
    "\n",
    "    if clean:\n",
    "        return result.dropna()\n",
    "    else:\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f984959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rogers_satchell(price_data, window=30, trading_periods=252, clean=True):\n",
    "    log_ho = (price_data[\"High\"] / price_data[\"Open\"]).apply(np.log)\n",
    "    log_lo = (price_data[\"Low\"] / price_data[\"Open\"]).apply(np.log)\n",
    "    log_co = (price_data[\"Close\"] / price_data[\"Open\"]).apply(np.log)\n",
    "\n",
    "    rs = log_ho * (log_ho - log_co) + log_lo * (log_lo - log_co)\n",
    "\n",
    "    def f(v):\n",
    "        return (trading_periods * v.mean()) ** 0.5\n",
    "\n",
    "    result = rs.rolling(window=window, center=False).apply(func=f)\n",
    "\n",
    "    if clean:\n",
    "        return result.dropna()\n",
    "    else:\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03add9a4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def yang_zhang(price_data, window=30, trading_periods=252, clean=True):\n",
    "    log_ho = (price_data[\"High\"] / price_data[\"Open\"]).apply(np.log)\n",
    "    log_lo = (price_data[\"Low\"] / price_data[\"Open\"]).apply(np.log)\n",
    "    log_co = (price_data[\"Close\"] / price_data[\"Open\"]).apply(np.log)\n",
    "\n",
    "    log_oc = (price_data[\"Open\"] / price_data[\"Close\"].shift(1)).apply(np.log)\n",
    "    log_oc_sq = log_oc ** 2\n",
    "\n",
    "    log_cc = (price_data[\"Close\"] / price_data[\"Close\"].shift(1)).apply(np.log)\n",
    "    log_cc_sq = log_cc ** 2\n",
    "\n",
    "    rs = log_ho * (log_ho - log_co) + log_lo * (log_lo - log_co)\n",
    "\n",
    "    close_vol = (\n",
    "        log_cc_sq.rolling(window=window, center=False).sum()\n",
    "        * (1.0 / (window - 1.0))\n",
    "    )\n",
    "    open_vol = (\n",
    "        log_oc_sq.rolling(window=window, center=False).sum()\n",
    "        * (1.0 / (window - 1.0))\n",
    "    )\n",
    "    window_rs = (\n",
    "        rs.rolling(window=window, center=False).sum()\n",
    "        * (1.0 / (window - 1.0))\n",
    "    )\n",
    "\n",
    "    k = 0.34 / (1.34 + (window + 1) / (window - 1))\n",
    "    result = (\n",
    "        (open_vol + k * close_vol + (1 - k) * window_rs).apply(np.sqrt)\n",
    "        * math.sqrt(trading_periods)\n",
    "    )\n",
    "\n",
    "    if clean:\n",
    "        return result.dropna()\n",
    "    else:\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b816e969",
   "metadata": {},
   "source": [
    "standard_deviation is the close-to-close baseline; hodges_tompkins debiases its small-sample downward bias from overlapping windows. parkinson and garman_klass use high–low (and open–close) ranges for higher efficiency; rogers_satchell is drift-robust, and yang_zhang blends overnight gap and intraday range to handle open–close discontinuities. These options let us see how bar-based measures react to spikes and gaps that closes miss, then pick a stable sizing input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3b9faf",
   "metadata": {},
   "source": [
    "## Visualize and compare volatility estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b5e0ec",
   "metadata": {},
   "source": [
    "Plot the close and all six estimators together to inspect when they agree and when they diverge around gaps, trend days, and stress. We care about relative timing and spikes more than exact levels on this axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a22b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Close\"].plot()\n",
    "standard_deviation(data).plot()\n",
    "parkinson(data).plot()\n",
    "garman_klass(data).plot()\n",
    "hodges_tompkins(data).plot()\n",
    "rogers_satchell(data).plot()\n",
    "yang_zhang(data).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674b9d94",
   "metadata": {},
   "source": [
    "The curves will not share units with price, so focus on how each estimator jumps and mean-reverts when regimes shift. In practice we would validate a candidate metric by comparing it to realized next-day moves or high–low ranges and then size positions off the most stable forecast. Watch for cases where close-vol looks calm while range-based measures surge; that mismatch is the failure mode we want to eliminate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f208f8b",
   "metadata": {},
   "source": [
    "<a href=\"https://pyquantnews.com/\">PyQuant News</a> is where finance practitioners level up with Python for quant finance, algorithmic trading, and market data analysis. Looking to get started? Check out the fastest growing, top-selling course to <a href=\"https://gettingstartedwithpythonforquantfinance.com/\">get started with Python for quant finance</a>. For educational purposes. Not investment advice. Use at your own risk."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
